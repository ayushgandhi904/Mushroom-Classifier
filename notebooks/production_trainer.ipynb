{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing for system\n",
    "import os, sys, pickle\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Production code Deployment Steps\n",
    "\n",
    "- Training pipeline\n",
    "1. Data Ingestion\n",
    "2. Data Transformation\n",
    "3. Model Evaulation \n",
    "\n",
    "- Predicted pipeline\n",
    "\n",
    "- Running in app"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For defining dataclass with Dataingestion config\n",
    "@dataclass\n",
    "class DataIngestionconfig:\n",
    "    train_data_path:str = os.path.join(\"artifacts\", \"train.csv\")\n",
    "    test_data_path:str = os.path.join(\"artifacts\", \"test.csv\")\n",
    "    raw_data_path:str = os.path.join(\"artifacts\", \"raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for data ingestion step \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data ingestion class\n",
    "\n",
    "class DataIngestion:\n",
    "    def __init__(self):\n",
    "        self.ingestion_config = DataIngestionconfig()\n",
    "        \n",
    "    \n",
    "    def initiate_data_ingestion(self):        \n",
    "        \n",
    "        df = pd.read_csv(os.path.join(\"data\", \"mushrooms.csv\"))\n",
    "        df[\"class\"] = df[\"class\"].apply(lambda x: {\"p\" : 1, \"e\": 0}[x])\n",
    "        \n",
    "        os.makedirs(os.path.dirname(self.ingestion_config.raw_data_path), exist_ok= True)\n",
    "        df.to_csv(self.ingestion_config.raw_data_path, index = False)\n",
    "        train_set, test_set = train_test_split(df, test_size = 0.3, random_state = 10)\n",
    "        \n",
    "        train_set.to_csv(self.ingestion_config.train_data_path, index = False, header = \"True\")\n",
    "        test_set.to_csv(self.ingestion_config.test_data_path, index = False, header = True)\n",
    "        \n",
    "        return(\n",
    "            self.ingestion_config.train_data_path,\n",
    "            self.ingestion_config.test_data_path\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for saving the object\n",
    "def save_object(file_path, obj):\n",
    "    dir_path = os.path.dirname(file_path)\n",
    "    \n",
    "    os.makedirs(dir_path, exist_ok= True)\n",
    "    \n",
    "    with open(file_path, \"wb\") as file_obj:\n",
    "        pickle.dump(obj, file_obj)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data class for data transformation\n",
    "@dataclass\n",
    "class DataTransformationConfig:\n",
    "    preprocessor_obj_file_path = os.path.join(\"artifacts\", \"preprocessor.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Data transformation\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class for Data Transformation\n",
    "class DataTransformation:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.data_transformation_config = DataTransformationConfig()\n",
    "        \n",
    "    def get_data_transformation_object(self):\n",
    "\n",
    "        lab_cols = ['cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor',\n",
    "                    'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color',\n",
    "                    'stalk-shape', 'stalk-root', 'stalk-surface-above-ring',\n",
    "                    'stalk-surface-below-ring', 'stalk-color-above-ring',\n",
    "                    'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number',\n",
    "                    'ring-type', 'spore-print-color', 'population', 'habitat']\n",
    "        \n",
    "        cap_shape = ['b','c','x','f','k','s']\n",
    "        cap_surface = ['f','g','y','s']\n",
    "        cap_color = ['n','b','c','g','r','p','u','e','w','y']\n",
    "        bruises = ['t','f']\n",
    "        odor = ['a','l','c','y','f','m','n','p','s']\n",
    "        gill_attachment = ['a','f']\n",
    "        gill_spacing = ['c','w']\n",
    "        gill_size = ['b','n']\n",
    "        gill_color = ['k','n','b','h','g','r','o','p','u','e','w','y']\n",
    "        stalk_shape = ['e','t']\n",
    "        stalk_root = ['b','c','e','r','?']\n",
    "        stalk_surface_above_ring = ['f','y','k','s']\n",
    "        stalk_surface_below_ring = ['f','y','k','s']\n",
    "        stalk_color_above_ring = ['n','b','c','g','o','p','e','w','y']\n",
    "        stalk_color_below_ring = ['n','b','c','g','o','p','e','w','y']\n",
    "        veil_type = ['p']\n",
    "        veil_color = ['w','n','o','y']\n",
    "        ring_number = ['n','o','t']\n",
    "        ring_type = ['e','f','l','n','p']\n",
    "        spore_print_color = ['k','n','b','h','r','o','u','w','y']\n",
    "        population = ['a','c','n','s','v','y']\n",
    "        habitat = ['g','l','m','p','u','w','d']\n",
    "        \n",
    "        target_pipeline = Pipeline(\n",
    "            steps = [\n",
    "                (\"ordinalencoder\", OrdinalEncoder(categories=[cap_shape, cap_surface, cap_color, bruises, odor, gill_attachment, gill_spacing, \n",
    "                                                                gill_size, gill_color, stalk_shape, stalk_root, stalk_surface_above_ring,\n",
    "                                                                stalk_surface_below_ring, stalk_color_above_ring, stalk_color_below_ring, veil_type,\n",
    "                                                                veil_color,ring_number, ring_type, spore_print_color, population, habitat])),\n",
    "                                                                \n",
    "                (\"PCA\", PCA(n_components=10))\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        preprocessor = ColumnTransformer([\n",
    "            (\"lab_pipeline\", target_pipeline, lab_cols)\n",
    "        ])\n",
    "        \n",
    "        return preprocessor\n",
    "                        \n",
    "    def initiate_data_transformation(self, train_path, test_path):\n",
    "\n",
    "        train_df = pd.read_csv(train_path)\n",
    "        test_df = pd.read_csv(test_path)\n",
    "\n",
    "        preprocessing_obj = self.get_data_transformation_object()\n",
    "        \n",
    "        target_column = \"class\"\n",
    "        drop_columns = [target_column]\n",
    "        \n",
    "        input_feature_train_df = train_df.drop(columns = drop_columns, axis = 1)\n",
    "        target_feature_train_df = train_df[target_column]\n",
    "        \n",
    "        input_feature_test_df = test_df.drop(columns = drop_columns, axis = 1)\n",
    "        target_feature_test_df = test_df[target_column]\n",
    "        \n",
    "        input_feature_train_arr = preprocessing_obj.fit_transform(input_feature_train_df)\n",
    "        input_feature_test_arr = preprocessing_obj.transform(input_feature_test_df)\n",
    "        \n",
    "        train_arr = np.c_[input_feature_train_arr, np.array(target_feature_train_df)]\n",
    "        test_arr = np.c_[input_feature_test_arr, np.array(target_feature_test_df)]\n",
    "        \n",
    "        save_object(\n",
    "            file_path=self.data_transformation_config.preprocessor_obj_file_path,\n",
    "            obj = preprocessing_obj\n",
    "        )\n",
    "        \n",
    "        return (\n",
    "            train_arr,\n",
    "            test_arr,\n",
    "            self.data_transformation_config.preprocessor_obj_file_path\n",
    "        ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for accuracy score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for evaluating the model\n",
    "def evaluate_model(X_train, y_train, X_test, y_test, models):\n",
    "    \n",
    "    report = {}\n",
    "    for i in range(len(models)):\n",
    "        model = list(models.values())[i]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        #Predicting value\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        \n",
    "        #getting accuracy score\n",
    "        test_model_score = accuracy_score(y_test, y_test_pred)\n",
    "        \n",
    "        report[list(models.keys())[i]] = test_model_score\n",
    "        \n",
    "    return report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For model evaluation\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data class for model evaluation\n",
    "@dataclass\n",
    "class ModelTrainerConfig:\n",
    "    trained_model_file_path = os.path.join(\"artifacts\", \"model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class for model trainer\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self):\n",
    "        self.model_trainer_config = ModelTrainerConfig()\n",
    "        \n",
    "    def initiate_model_training(self, train_array, test_array):\n",
    "        \n",
    "        X_train, y_train, X_test, y_test = (\n",
    "            train_array[:,:-1],\n",
    "            train_array[:, -1],\n",
    "            test_array[:, :-1],\n",
    "            test_array[:, -1]\n",
    "        )\n",
    "        \n",
    "        models = {\n",
    "            \"LogisticRegression\" : LogisticRegression(),\n",
    "            \"LogisticRegressionCV\" : LogisticRegressionCV(),\n",
    "            \"KNN\" : KNeighborsClassifier(),\n",
    "            \"Decision Tree\" : DecisionTreeClassifier(),\n",
    "            \"SVC\" : SVC(),\n",
    "            \"RandomForest\" : RandomForestClassifier(),\n",
    "            \"GradientBoosting\" : GradientBoostingClassifier()\n",
    "            \n",
    "        }\n",
    "        \n",
    "        model_report:dict=evaluate_model(X_train, y_train, X_test, y_test, models)\n",
    "        print(model_report)\n",
    "\n",
    "        best_model_score = max(sorted(model_report.values()))\n",
    "        \n",
    "        best_model_name = list(model_report.keys())[\n",
    "            list(model_report.values()).index(best_model_score)\n",
    "        ]\n",
    "        \n",
    "        best_model = models[best_model_name]\n",
    "        \n",
    "        save_object(\n",
    "            \n",
    "            file_path = self.model_trainer_config.trained_model_file_path,\n",
    "            obj = best_model\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting with Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LogisticRegression': 0.8613617719442166, 'LogisticRegressionCV': 0.8584905660377359, 'KNN': 0.9995898277276456, 'Decision Tree': 0.9856439704675964, 'SVC': 0.9971287940935193, 'RandomForest': 0.9987694831829368, 'GradientBoosting': 0.9840032813781788}\n"
     ]
    }
   ],
   "source": [
    "#to connect all above with pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    obj = DataIngestion()\n",
    "    train_data_path, test_data_path = obj.initiate_data_ingestion()\n",
    "    \n",
    "    data_transformation = DataTransformation()\n",
    "    train_arr, test_arr, _ = data_transformation.initiate_data_transformation(train_data_path, test_data_path)\n",
    "    \n",
    "    model_trainer=ModelTrainer()\n",
    "    model_trainer.initiate_model_training(train_arr,test_arr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to load data\n",
    "def load_object(file_path):\n",
    "    \n",
    "    with open(file_path, \"rb\") as file_obj:\n",
    "        return pickle.load(file_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class for predicting pipeline\n",
    "\n",
    "class PredictPipeline:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass    \n",
    "    def predict(self, features):\n",
    "        \n",
    "        preprocessor_path = os.path.join(\"artifacts\", \"preprocessor.pkl\")\n",
    "        model_path = os.path.join(\"artifacts\", \"model.pkl\")\n",
    "        \n",
    "        preprocessor = load_object(preprocessor_path)\n",
    "        model = load_object(model_path)\n",
    "        \n",
    "        data_scaled = preprocessor.transform(features)\n",
    "        \n",
    "        pred = model.predict(data_scaled)\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom data class with the form\n",
    "\n",
    "class CustomData:\n",
    "    \n",
    "    def __init__(self,\n",
    "                 cap_shape:str,\n",
    "                 cap_surface:str,\n",
    "                 cap_color:str,\n",
    "                 bruises:str,\n",
    "                 odor:str,\n",
    "                 gill_attachment:str,\n",
    "                 gill_spacing:str,\n",
    "                 gill_size:str,\n",
    "                 gill_color:str,\n",
    "                 stalk_shape:str,\n",
    "                 stalk_root:str,\n",
    "                 stalk_surface_above_ring:str,\n",
    "                 stalk_surface_below_ring:str,\n",
    "                 stalk_color_above_ring:str,\n",
    "                 stalk_color_below_ring:str,\n",
    "                 veil_type:str,\n",
    "                 veil_color:str,\n",
    "                 ring_number:str,\n",
    "                 ring_type:str,\n",
    "                 spore_print_color:str,\n",
    "                 population:str,\n",
    "                 habitat:str):\n",
    "        \n",
    "        self.cap_shape = cap_shape\n",
    "        self.cap_surface = cap_surface\n",
    "        self.cap_color = cap_color\n",
    "        self.bruises = bruises\n",
    "        self.odor = odor\n",
    "        self.gill_attachment = gill_attachment\n",
    "        self.gill_spacing = gill_spacing\n",
    "        self.gill_size = gill_size\n",
    "        self.gill_color = gill_color\n",
    "        self.stalk_shape = stalk_shape\n",
    "        self.stalk_root = stalk_root\n",
    "        self.stalk_surface_above_ring = stalk_surface_above_ring\n",
    "        self.stalk_surface_below_ring = stalk_surface_below_ring\n",
    "        self.stalk_color_above_ring = stalk_color_above_ring\n",
    "        self.stalk_color_below_ring = stalk_color_below_ring\n",
    "        self.veil_type = veil_type\n",
    "        self.veil_color = veil_color\n",
    "        self.ring_number = ring_number\n",
    "        self.ring_type = ring_type\n",
    "        self.spore_print_color = spore_print_color\n",
    "        self.population = population\n",
    "        self.habitat = habitat\n",
    "        \n",
    "    \n",
    "    def get_data_as_dataframe(self):\n",
    "        \n",
    "        custom_data_input_dict = {\n",
    "            \"cap-shape\" : [self.cap_shape],\n",
    "            \"cap-surface\" : [self.cap_surface],\n",
    "            \"cap-color\" : [self.cap_color],\n",
    "            \"bruises\" : [self.bruises],\n",
    "            \"odor\" : [self.odor],\n",
    "            \"gill-attachment\" : [self.gill_attachment],\n",
    "            \"gill-spacing\" : [self.gill_spacing],\n",
    "            \"gill-size\" : [self.gill_size],\n",
    "            \"gill-color\" : [self.gill_color],\n",
    "            \"stalk-shape\" : [self.stalk_shape],\n",
    "            \"stalk-root\" : [self.stalk_root],\n",
    "            \"stalk-surface-above-ring\" : [self.stalk_surface_above_ring],\n",
    "            \"stalk-surface-below-ring\" : [self.stalk_surface_below_ring],\n",
    "            \"stalk-color-above-ring\" : [self.stalk_color_above_ring],\n",
    "            \"stalk-color-below-ring\" : [self.stalk_color_below_ring],\n",
    "            \"veil-type\" : [self.veil_type],\n",
    "            \"veil-color\" : [self.veil_color],\n",
    "            \"ring-number\" : [self.ring_number],\n",
    "            \"ring-type\" : [self.ring_type],\n",
    "            \"spore-print-color\" : [self.spore_print_color],\n",
    "            \"population\" : [self.population],\n",
    "            \"habitat\" : [self.habitat]      \n",
    "        }\n",
    "        df = pd.DataFrame(custom_data_input_dict)\n",
    "        return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# App runner\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for flask & app runner\n",
    "from flask import Flask,request,render_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.43.246:5000\n",
      "Press CTRL+C to quit\n"
     ]
    }
   ],
   "source": [
    "application=Flask(__name__)\n",
    "\n",
    "app=application\n",
    "\n",
    "@app.route('/')\n",
    "def home_page():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route(\"/predict\", methods = [\"GET\", \"POST\"])\n",
    "\n",
    "def predict_datapoint():\n",
    "    if request.method == \"GET\":\n",
    "        return render_template(\"form.html\")\n",
    "    \n",
    "    else:\n",
    "        data = CustomData(\n",
    "            cap_shape = request.form.get(\"cap_shape\"),\n",
    "            cap_surface = request.form.get(\"cap_surface\"),\n",
    "            cap_color = request.form.get(\"cap_color\"),\n",
    "            bruises = request.form.get(\"bruises\"),\n",
    "            odor = request.form.get(\"odor\"),\n",
    "            gill_attachment = request.form.get(\"gill_attachment\"),\n",
    "            gill_spacing = request.form.get(\"gill_spacing\"),\n",
    "            gill_size = request.form.get(\"gill_size\"),\n",
    "            gill_color = request.form.get(\"gill_color\"),\n",
    "            stalk_shape = request.form.get(\"stalk_shape\"),\n",
    "            stalk_root = request.form.get(\"stalk_root\"),\n",
    "            stalk_color_above_ring = request.form.get(\"stalk_color_above_ring\"),\n",
    "            stalk_color_below_ring = request.form.get(\"stalk_color_below_ring\"),\n",
    "            stalk_surface_above_ring = request.form.get(\"stalk_surface_above_ring\"),\n",
    "            stalk_surface_below_ring = request.form.get(\"stalk_surface_below_ring\"),\n",
    "            veil_type = request.form.get(\"veil_type\"),\n",
    "            veil_color = request.form.get(\"veil_color\"),\n",
    "            ring_number = request.form.get(\"ring_number\"),\n",
    "            ring_type = request.form.get(\"ring_type\"),\n",
    "            spore_print_color = request.form.get(\"spore_print_color\"),\n",
    "            population = request.form.get(\"population\"),\n",
    "            habitat = request.form.get(\"habitat\")            \n",
    "        )\n",
    "        \n",
    "        final_new_data = data.get_data_as_dataframe()\n",
    "        predict_pipeline = PredictPipeline()\n",
    "        pred = predict_pipeline.predict(final_new_data)\n",
    "        \n",
    "        if pred == 0:\n",
    "            results = \"Edible\"\n",
    "            return render_template(\"edible.html\", final_result = results)\n",
    "        elif pred == 1:\n",
    "            results = \"Poisonous\"\n",
    "            return render_template(\"poisonous.html\", final_result = results)\n",
    "        else:\n",
    "            result = \"Data not found\"\n",
    "            return render_template(\"results.html\", final_result = results)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    app.run(host='0.0.0.0',port=5000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
